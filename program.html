<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>ICRA 2019 Workshop, Long-term Human Motion Prediction</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Long-term Human Motion Prediction</strong></a>
									<!-- <ul class="icons">
										<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon fa-medium"><span class="label">Medium</span></a></li>
									</ul>
									-->
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>Long-term Human Motion Prediction<br />
											Workshop ICRA 2019</h1>
											<p>ICRA 2019, Montreal, Canada</p>
											<p>May 24, 2019, 8:30-17:30<br>Room 520a</p>
										</header>
										<!-- <p>Aenean ornare velit lacus, ac varius enim ullamcorper eu. Proin aliquam facilisis ante interdum congue. Integer mollis, nisl amet convallis, porttitor magna ullamcorper, amet egestas mauris. Ut magna finibus nisi nec lacinia. Nam maximus erat id euismod egestas. Pellentesque sapien ac quam. Lorem ipsum dolor sit nullam.</p>
										<ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul> -->
									</div>
									<!-- span class="image object">
										<img src="images/pic10.jpg" alt="" />
									</span -->
								</section>

							    <section>
									<header class="major">
									<h2>Program</h2>
									</header>
									<p>The event will be split into two parts. The first part are talks of invited speakers, which will present state-of-the-art in the related fields and define open research questions. The second part covers a poster session of submitted papers. Here
follows a tentative program.</p>
								<div class="table-wrapper">
														<table>
															<thead>
																<tr>
																	<th>Time</th>
																	<th>Talk</th>
																</tr>
															</thead>
															<tbody>
																<tr>
																	<td>8:30 - 8:45</td>
																	<td>Welcome and Introduction</td>
																</tr>
																<tr>
																	<td>8:45 - 9:10</td>
																	<td><a href="https://scholar.google.com/citations?user=BlSfMYwAAAAJ&hl=en">Andrey Rudenko, Robert Bosch GmbH Corporate Research</a>
																		<br>
																		<h4>Human motion Prediction: Problems, Methods and Challenges</h4>
																		<div>With growing numbers of intelligent systems in human environments, the ability of such systems to perceive, understand and anticipate human behavior becomes increasingly important. Specifically, predicting future positions of dynamic agents and planning considering such predictions are important tasks for intelligent vehicles, service robots and advanced visual surveillance systems. What makes this task challenging is that human motion is influenced by a large variety of factors, including the person’s intention, the presence, attributes and actions of other surrounding agents, the geometry and semantics of the environment. In this talk, I will present our current results on surveying, analyzing and addressing the human motion prediction problem. First part of the talk summarizes a comprehensive analysis of the literature, where we categorize existing methods, propose a new taxonomy, discuss limitations of the state-of-the-art approaches and outline the open challenges. In the second part of the talk, I will highlight some of our research on predicting long-term motion of people in public spaces, learning occupancy priors in urban environments and benchmarking predicted trajectories. <br><a href="https://arxiv.org/abs/1905.06113">Link to the survey on human motion prediction techniques</a> </div>
																		<br><a href="ppts/rudenko.pdf">Slides</a>
																	</td>
																</tr>
																<tr>
																	<td>9:10 - 09:35</td>
																	<td><a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha, University of Maryland at College Park</a><br>
																	<h4>Prediction of Human Motion and Traffic Agents in Dense Environments</h4>
																	<div>We give an overview of our recent work on predicting the trajectories of pedestrian agents in a crowd and traffic agents (cars, bicycles, buses, pedestrians) in a dense setting. Our approach combines model-based methods that take into account geometric shape, dynamics, and behavior of each agent and combine them with learning-based methods that use deep neural networks. We are able to track the trajectory of each agent based on a single camera video in realtime and predict their trajectories over short-term (1-3 seconds) and long-term durations (4-6 seconds). In practice, our approach can model dense human crowds as well as heterogeneous, urban traffic videos. We will highlight the performance on many challenging scenarios and highlight many open issues for future work. Joint work with GAMMA group members at the University of Maryland at College Park</div>
																	<br><a href="ppts/manocha.pdf">Slides</a>
																	</td>
																</tr>
																<tr>
																	<td>9:35 - 10:00</td>
																	<td>Pitch Talks of Papers 1, 2, 3, 4, 5</td>
																</tr>																

																<tr>
																	<td>10:00 - 10:30</td>
																	<td>Coffee break</td>
																</tr>
																<tr>
																	<td>10:30 - 10:55</td>
																	<td><a href="http://cvrr.ucsd.edu/">Mohan Trivedi, UC San Diego</a>
																	<br>
																	<h4>On Understanding Human Motion, Activities and Intentions for Safe Autonomous Driving</h4>
																	<div>These are truly exciting times, especially for researchers and scholars active in robotics and intelligent systems. Fruits of their labor are enabling transformative changes in daily lives of the general public. In this presentation we will focus on changes affecting our mobility on
roads with highly automated intelligent vehicles. Autonomous driving is no longer confined to
science fiction or specialized research laboratories, but is offered for the general public to ride.
We discuss issues related to the understanding of human agents interacting with the automated
vehicle, either as occupants of such vehicles, or in their vicinity, as pedestrians, cyclists, or
inside surrounding vehicles. These issues require deeper examination and careful resolution to
assure safety, reliability and robustness of these highly complex systems for operation on
public roads. The presentation will highlight recent research dealing with understanding of
activities, behavior, intentions of humans specifically in the context of autonomous driving.<br><a href="http://cvrr.ucsd.edu/publications/index.html">Links to related papers</a></div>
																	</td>
																</tr>
																<tr>
																	<td>10:55 - 11:20</td>
																	<td><a href="https://vita.epfl.ch/">Alexandre Massoud Alahi, EPFL</a>
																	<br>
																	<h4>Forecasting Human Mobility with Deep Learning: Challenges and Recipes</h4>
																	<div>Over the recent years, various deep learning based forecasting models have been proposed to predict human motion behaviours - the unspoken social rules of mobility. In this talk, I will review state-of-the-art models based on LSTM, GAN, and MLP, share their limitations, and present some of our on-going works to address them.</div>
																	<br><a href="ppts/alahi.pdf">Slides</a>
																	</td>
																</tr>
																<tr>
																	<td>11:20 - 11:45</td>
																	<td><a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu, National University of Singapore</a><br> 
																		<h4>Motion Prediction for Autonomous Driving in Dense Traffic </h4>
																		<div>Motion prediction of pedestrians and vehicles is critical for autonomous driving. For accurate prediction, we must account for (i) the agent's intention, (ii) physical motion constraints, and (iii)  interaction with a heterogeneous set of other agents, including both pedestrians and various types of  vehicles, More importantly, motion prediction must be integrated with decision making  to enable autonomous driving. In this talk, I will discuss our work on extending the ORCA model for motion prediction of pedestrians and vehicles and using the extended model within a partially observable Markov decision process (POMDP) for real-time online decision-making in dynamic environments.</div>
																	</td>
																</tr>
																<tr>
																	<td>11:45 - 12:45</td>
																	<td>Pitch talks of Papers 6, 7, 8, 9, 10<br>Poster session</td>
																</tr>
																<tr>
																	<td>12:45 - 13:45</td>
																	<td>Lunch</td>
																</tr>
																<tr>
																	<td>13:45 - 14:10</td>
																	<td><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/HRM/">Jim Mainprice, University of Stuttgart</a>
																	<br>
																	<h4>Human Motion Prediction for "Human-Aware" Robots</h4>
																	<div>Conceptualizing control architectures that account explicitly for the human is both challenging and of fundamental importance to robotics. However to this day, despite decades of efforts in motion planning and control, mobile manipulators still fail to achieve human-level coordination regarding other humans in their environments. In this talk I will present on going work to bridge this gap integrating human motion prediction and model predictive control. This approach allows to consider the intricate human-robot behavior robustly. To motivate this approach, I will present some work on handover tasks where the robot proactively plans solutions that involve human movement. I will then show how human space sharing criteria can be extracted from interactive human motion capture using inverse optimal control. Finally, I will go over recent work where motion capture data is used to derive short-term dynamical models encoding full body human movement that can be combined with trajectory optimization once the high-level intent is identified. I will conclude by introducing a robot architecture that can take these predictions into account.</div>
																	<br><a href="ppts/mainprice.pdf">Slides</a>
																	</td>
																</tr>
																<tr>
																	<td>14:10 - 14:35</td>
																	<td><a href="https://www.cs.ubc.ca/~van/">Michiel van de Panne, University of British Columbia</a>
																	<br>
																	<h4>Physics-based Human Movement: Shared Models for Animation, Robotics, Vision, and Biomechanics</h4>
																	<div>Recent advances in reinforcement learning have provided a powerful framework for designing the control that enables human simulations and robots to move with skill and grace.  We review a recent physics-based imitation model and describe its direct application to the problems of prediction and control, as applied to computer vision, robotics, biomechanics, and computer animation. We discuss some of the challenges for achieving further scalability for these models. </div>
																	<br><a href="ppts/vandepanne.pdf">Slides</a>
																	</td>
																</tr>
																<tr>
																	<td>14:35 - 15:00</td>
																	<td><a href="http://web.csulb.edu/colleges/coe/mae/faculty/demircan.shtml">Emel Demircan, California State University Long Beach</a>
																	<h4>Understanding Human Perception in Manipulation and Locomotion Skills</h4>
																	<div>Human motor performance is a key area of investigation in biomechanics, robotics, and machine learning. Understanding human neuromuscular control is important to synthesize prosthetic motions and ensure
safe human-robot interaction. Building controllable biomechanical models through
modeling and algorithmic tools from both robotics and biomechanics increases our
scientific understanding of musculoskeletal mechanics and control. The resulting
models can consequently help quantifying the characteristics of a subject’s motion
and in designing effective treatments, like predictive simulations and motion
training. My objective is to explore how neural control dictates motor performance
in humans by developing a portable, soft, cyber-physical system and a
computational framework - which incorporates real-time robotics-based control, AIbased
perception and learning, and OpenSim’s musculoskeletal models. In this
talk, I will present the modeling, control, and simulation components of this new
framework with two examples on human manipulation and locomotion skills. The
presented framework has promise to advance the field of rehabilitation robotics by
deepening our scientific understanding of human motor performance dictated by
musculoskeletal physics and neural control. Automated and real-time motion
improvement and retraining, facilitated with such frameworks, promise to
transform the neuromuscular health, longevity, and independence of millions of
people, utilizing a cost effective approach.</div>
																	</td>
																</tr>
																<tr>
																	<td>15:00 - 15:30</td>
																	<td>Coffee break</td>
																</tr>
																<tr>
																	<td>15:30 - 15:55</td>
																	<td><a href="http://people.eecs.berkeley.edu/~abajcsy/">Andrea Bajcsy, Berkeley</a>
																	<br>
																	<h4>Confidence-aware Motion Prediction for Real-time Collision Avoidance</h4>
																	<div>One of the most difficult challenges in robot motion planning is to account for the behavior of other moving agents, such as humans. Commonly, practitioners employ predictive models to reason about where other agents are going to move. Though there has been much recent work in building predictive models, no model is ever perfect: an agent can always move unexpectedly, in a way that is not predicted or not assigned sufficient probability. In such cases, the robot may plan trajectories that appear safe but in fact lead to collision. Rather than trust a model’s predictions blindly, we propose that the robot should use the model’s current predictive accuracy to inform the degree of confidence in its future predictions. This model confidence inference allows us to generate probabilistic motion predictions that exploit modeled structure when the structure successfully explains human motion, and degrade gracefully whenever the human moves unexpectedly. In this talk I will discuss how we accomplish this by maintaining a Bayesian belief over a single parameter which governs the variance of our human motion model. We couple this prediction algorithm with a recently-proposed robust motion planner and controller to guide the construction of robot trajectories which are, to a good approximation, collision-free with a high, user-specified probability. I will also discuss the overall safety properties of this approach by establishing a connection to reachability analysis, and conclude with recent work on scaling up this framework for multi-robot, multi-human collision avoidance.</div>
																	<br><a href="ppts/abajcsy.pdf">Slides</a>
																	</td>
																</tr>
																<tr>
																	<td>15:55 - 16:20</td>
																	<td><a href="http://web.stanford.edu/~schmrlng/">Edward Schmerling, Stanford</a>
																	<br>
																	<h4>Mitigating the "Element of Surprise" in Model-Based Robot Planning</h4>
																	<div>Taking into account the full breadth of possibilities in how humans may respond to a robot's actions is a key component of enabling safe, anticipatory, and proactive robot interaction policies. By reasoning in the present about the relative likelihoods of multiple highly distinct future outcomes, a robot can hope to avoid costly surprises that might arise from optimizing against, e.g., a single most likely prediction. In this talk I will first give an overview of our recent work in learning deep generative trajectory prediction models amenable to planning applications in multi-agent scenarios where surrounding agents may dynamically come into and out of relevance. Then, in the context of enabling safer autonomous driving, I will describe our experimental work in incorporating these models into a planning framework with a minimally interventional safety controller that accounts for a further class of "surprises" --- when human actions consistently defy the robot's predictive distributions. </div>
																	<br><a href="ppts/schmerling.pdf">Slides</a>
																	</td>
																</tr>
																<tr>
																	<td>16:20 - 16:45</td>
																	<td>Closing</td>
																</tr>																
															</tbody>
														</table>
													</div>

								</section>
								<section>
									<header class="major">
										<h2>Accepted Papers for Pitch Talks</h2>
									</header>
									<p>The accepted papers will be presented during the 2 pitch talks - posters sessions. Each paper will be presented in a short 3 minutes talk. The following table reports the order of presentations: the first five papers will be presented during the first pitch talk session (starting at 9:35), the second will start around 11:45. Right after the second pitch talks, a poster session for all the papers will be held in the same room.</p>
									<div class="table-wrapper">
														<table>
															<thead>
																<tr>
																	<th>Number, time</th>
																	<th>Name</th>
																	<th>Authors</th>															
																</tr>
															</thead>
															<tbody>
																<tr>
																	<td>1</td>
																	<td><a href="papers/LHMP19_paper_1.pdf">SE(3) Multimotion Estimation Through Occlusion</a></td>
																	<td>Kevin Judd and Jonathan Gammell</td>
																</tr>
																<tr>
																	<td>2</td>
																	<td><a href="papers/LHMP19_paper_2.pdf">Spatiotemporal Learning of Directional Uncertainty in Urban Environments</a></td>
																	<td>Weiming Zhi, Ransalu Senanayake, Lionel Ott and Fabio Ramos</td>
																</tr>
																<tr>
																	<td>3</td>
																	<td><a href="papers/LHMP19_paper_4.pdf">Schedule-based Motion Prediction for Human-Centric Autonomous Observation</a></td>
																	<td>David Kent and Sonia Chernova</td>
																</tr>
																<tr>
																	<td>4</td>
																	<td><a href="papers/LHMP19_paper_5.pdf">The Emotionally Intelligent Robot: Improving Socially-aware Human Prediction in Crowded Environments</a></td>
																	<td>Aniket Bera, Tanmay Randhavane and Dinesh Manocha</td>
																</tr>
																<tr>
																	<td>5</td>
																	<td><a href="papers/LHMP19_paper_6.pdf">Human Motion Prediction Framework for Safe Flexible Robotized Warehouses</a></td>
																	<td>Tomislav Petković, Jakub Hvězda, Tomáš Rybecký, Ivan Marković, Miroslav Kulich, Libor Přeučil and Ivan Petrović</td>
																</tr>
																<tr>
																	<td>6</td>
																	<td><a href="papers/LHMP19_paper_7.pdf">Dynamic Hilbert Maps: Real-Time Occupancy Predictions in Changing Environments</a></td>
																	<td>Vitor Guizilini, Ransalu Senanayake and Fabio Ramos</td>
																</tr>
																<tr>
																	<td>7</td>
																	<td><a href="papers/LHMP19_paper_10.pdf">Using Maximum Entropy Deep Inverse Reinforcement Learning to Learn Personalized Navigation Strategies</a></td>
																	<td>Abhisek Konar, Bobak Hamed Baghi and Gregory Dudek</td>
																</tr>
																<tr>
																	<td>8</td>
																	<td><a href="papers/LHMP19_paper_11.pdf">An Integrative Approach of Social Dynamic Long Short-Term Memory and Deep Reinforcement Learning for Socially Aware Robot Navigation</a></td>
																	<td>Xuan-Tung Truong and Trung Dung Ngo</td>
																</tr>
																<tr>
																	<td>9</td>
																	<td><a href="papers/LHMP19_paper_13.pdf">Scene Induced Multi-Modal Trajectory Forecasting via Planning</a></td>
																	<td>Nachiket Deo and Mohan Trivedi</td>
																</tr>
																<tr>
																	<td>10</td>
																	<td><a href="papers/LHMP19_paper_14.pdf">Spatio-temporal Representation of Time-varying Pedestrian Flows</a></td>
																	<td>Tomas Vintr, Sergi Molina, Ransalu Senanayake, George Broughton, Zhi Yan, Jiri Ulrich, Tomasz Piotr Kucner, Chittaranjan Srinivas Swaminathan, Filip Majer, Maria Stachova, Achim Lilienthal and Tomáš Krajník</td>
																</tr>
																
															</tbody>
														</table>
													</div>
									
								</section>
								<section>
									<header class="major">
										<h2>Intended audience</h2>
									</header>
									<p>The topic of human motion prediction is of interest for researchers from different scientific areas, such as motion planning, learning and control, human-robot
interaction, intelligent transportation systems and computer vision. However, it is rarely in the spotlight and is usually treated as small and single component part of a larger research problem. This workshop aims to build a platform
for researchers interested in the development of reliable motion prediction approaches and tools to evaluate their performance and quality. It will feature a diverse set of high-profile invited speakers both form academia and industry.
Their expertise is covering a wide spectrum of topics, including computer vision, human-robot interaction, autonomous vehicles.		</p>	
								</section>
								
								
							<!-- Section 
								<section>
									<header class="major">
										<h2>Ipsum sed dolor</h2>
									</header>
									<div class="posts">
										<article>
											<a href="#" class="image"><img src="images/pic01.jpg" alt="" /></a>
											<h3>Interdum aenean</h3>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
											<ul class="actions">
												<li><a href="#" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic02.jpg" alt="" /></a>
											<h3>Nulla amet dolore</h3>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
											<ul class="actions">
												<li><a href="#" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic03.jpg" alt="" /></a>
											<h3>Tempus ullamcorper</h3>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
											<ul class="actions">
												<li><a href="#" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic04.jpg" alt="" /></a>
											<h3>Sed etiam facilis</h3>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
											<ul class="actions">
												<li><a href="#" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic05.jpg" alt="" /></a>
											<h3>Feugiat lorem aenean</h3>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
											<ul class="actions">
												<li><a href="#" class="button">More</a></li>
											</ul>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic06.jpg" alt="" /></a>
											<h3>Amet varius aliquam</h3>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
											<ul class="actions">
												<li><a href="#" class="button">More</a></li>
											</ul>
										</article>
									</div>
								</section>
				-->
						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
										<li><a href="program.html">Program</a></li>
										<li><a href="callforpapers.html">Call for Papers</a></li>
										<li><a href="interact.html">Interact With Us</a></li>

										<!-- <li><a href="generic.html">Generic</a></li> -->
										<!-- <li><a href="elements.html">Elements</a></li> -->
										<!--
										<li>
											<span class="opener">Submenu</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li><a href="#">Etiam Dolore</a></li>
										<li><a href="#">Adipiscing</a></li>
										<li>
											<span class="opener">Another Submenu</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li><a href="#">Maximus Erat</a></li>
										<li><a href="#">Sapien Mauris</a></li>
										<li><a href="#">Amet Lacinia</a></li>
										-->
									</ul>
								</nav>

							<!-- Section 
								<section>
									<header class="major">
										<h2>Ante interdum</h2>
									</header>
									<div class="mini-posts">
										<article>
											<a href="#" class="image"><img src="images/pic07.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic08.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic09.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
									</div>
									<ul class="actions">
										<li><a href="#" class="button">More</a></li>
									</ul>
								</section>
							-->
							<!-- Section 
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Sed varius enim lorem ullamcorper dolore aliquam aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin sed aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p>
									<ul class="contact">
										<li class="fa-envelope-o"><a href="#">information@untitled.tld</a></li>
										<li class="fa-phone">(000) 000-0000</li>
										<li class="fa-home">1234 Somewhere Road #8254<br />
										Nashville, TN 00000-0000</li>
									</ul>
								</section>
							-->
							<!-- Footer 
								<footer id="footer">
									<p class="copyright">&copy; Untitled. All rights reserved. Demo Images: <a href="https://unsplash.com">Unsplash</a>. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>
							-->
						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>